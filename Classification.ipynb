{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hybrid-margin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "791\n",
      "951\n",
      "3809\n"
     ]
    }
   ],
   "source": [
    "#import packages and image data\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as spio\n",
    "import scipy.sparse.linalg as ll\n",
    "import sklearn.preprocessing as skpp\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import sklearn.utils.graph_shortest_path as sk\n",
    "import scipy.sparse.linalg as ll\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import the images\n",
    "from PIL import Image\n",
    "import zipfile\n",
    "from zipfile import ZipFile\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "\n",
    "#import Mars orbital images\n",
    "# specifying the zip file name\n",
    "file_name = \"map-proj.zip\"\n",
    "#create a data array of images where each row is a vectorized version of an image\n",
    "archive = zipfile.ZipFile('map-proj.zip', 'r')\n",
    "imagefile = archive.open(archive.namelist()[0])\n",
    "img=Image.open(imagefile)\n",
    "numpydata = np.asarray(img)\n",
    "data=numpydata.reshape(1, 227*227) #create first row of data\n",
    "# create the rest of the rows of data\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "    for i in range(1,3823):\n",
    "        imagefile = zip.open(zip.namelist()[i])\n",
    "        img=Image.open(imagefile)\n",
    "        numpydata = np.asarray(img)\n",
    "        imgarray=numpydata.reshape(1, 227*227)\n",
    "        data=np.concatenate((data,imgarray), axis=0)\n",
    "\n",
    "#remove the rows 791, 951, 3809 because they have no labels\n",
    "data = np.delete(data,[791,951,3809],0)\n",
    "# archive = zipfile.ZipFile('map-proj.zip', 'r')\n",
    "# imgfile = archive.open('map-proj/PSP_009754_2205_RED-0031.jpg')\n",
    "# imgfile\n",
    "\n",
    "# pic=data[0,:]\n",
    "# pic=np.reshape(pic,(227,227))\n",
    "# pic = (pic).astype(np.uint8)\n",
    "# im = Image.fromarray(pic,mode='L')\n",
    "\n",
    "#im.show()\n",
    "#im.save('result.png')\n",
    "\n",
    "#create a dictionary that maps label to category name\n",
    "class_map = {0: 'other',\n",
    "             1: 'crater',\n",
    "             2: 'dark_dune',\n",
    "             3: 'streak',\n",
    "             4: 'bright_dune',\n",
    "             5: 'impact',\n",
    "             6: 'edge'}\n",
    "\n",
    "# create reverse dictionary\n",
    "reverse_class_map = {v: k for k,v in class_map.items()}\n",
    "\n",
    "#upload the labels as pd dataframe\n",
    "labels_df = pd.read_csv('labels-map-proj.txt', sep=\" \", header=None)\n",
    "labels_df.columns = [\"name\",'label']\n",
    "labels_df\n",
    "\n",
    "#create an np array of labels that corresponds to the rows in data (labels_df is in different order from data)\n",
    "#also print out the three rows that have no label\n",
    "labels_list=[]\n",
    "for i in range(3823):\n",
    "    name = archive.namelist()[i].split('map-proj/')[1] \n",
    "    if name in set(labels_df['name']):\n",
    "        labels_list.append([int(labels_df.loc[labels_df['name']==name]['label'])])\n",
    "    else:\n",
    "        print(i)\n",
    "labels=np.array(labels_list)\n",
    "\n",
    "#create dataset consisting of 'crater', 'dark dune', 'streak', and 'bright dune' only\n",
    "indices_main=np.where(labels==[1,2,3,4])[0]\n",
    "data_main=data[indices_main]\n",
    "labels_main=labels[indices_main] #create corresponding labels for data_main\n",
    "\n",
    "#create dataset for only the 'other' category\n",
    "indices_other=np.where(labels==0)[0]\n",
    "data_other=data[indices_other]\n",
    "labels_other=labels[indices_other] #create corresponding labels for data_other\n",
    "\n",
    "#create dataset for only the 'crater' category\n",
    "indices_crater=np.where(labels==1)[0]\n",
    "data_crater=data[indices_crater]\n",
    "labels_crater=labels[indices_crater] #create corresponding labels for data_crater\n",
    "\n",
    "#create dataset for only the 'dark dune' category\n",
    "indices_dark=np.where(labels==2)[0]\n",
    "data_dark=data[indices_dark]\n",
    "labels_dark=labels[indices_dark] #create corresponding labels for data_dark\n",
    "\n",
    "#create dataset for only the 'bright dune' category\n",
    "indices_bright=np.where(labels==4)[0]\n",
    "data_bright=data[indices_bright]\n",
    "labels_bright=labels[indices_bright] #create corresponding labels for data_bright\n",
    "\n",
    "#create dataset for only the 'streak' category\n",
    "indices_streak=np.where(labels==3)[0]\n",
    "data_streak=data[indices_streak]\n",
    "labels_streak=labels[indices_streak] #create corresponding labels for data_streak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "coastal-ethernet",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define X and Y using data_main\n",
    "X = data_main\n",
    "labels_main=np.reshape(labels_main,(970,))\n",
    "Y = labels_main\n",
    "\n",
    "#Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.2, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "genuine-ontario",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale by 255\n",
    "X_train=X_train/255\n",
    "X_test=X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "integral-evolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pleasant-department",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.634020618556701\n",
      "[[56 11  4  2]\n",
      " [16 57  0 11]\n",
      " [ 0  1  2  1]\n",
      " [14  6  5  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.77      0.70        73\n",
      "           2       0.76      0.68      0.72        84\n",
      "           3       0.18      0.50      0.27         4\n",
      "           4       0.36      0.24      0.29        33\n",
      "\n",
      "    accuracy                           0.63       194\n",
      "   macro avg       0.49      0.55      0.49       194\n",
      "weighted avg       0.64      0.63      0.63       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#perform logistic regression\n",
    "\n",
    "#Fitting Logistic Regression to the Training set\n",
    "classifier = LogisticRegression(max_iter=20000)\n",
    "classifier.fit(X_train,Y_train)\n",
    "\n",
    "#Predicting the Test set results\n",
    "Y_pred = classifier.predict(X_test)\n",
    "\n",
    "#Making the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm.trace()/len(Y_test))\n",
    "print(cm)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hybrid-portuguese",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "{'n_neighbors': 3}\n",
      "Accuracy for our training dataset with tuning is : 71.90%\n"
     ]
    }
   ],
   "source": [
    "#Perform cross validation to find the optimal number of neighbors\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "k_range = list(range(1, 31))\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "  \n",
    "# defining parameter range\n",
    "grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy', return_train_score=False,verbose=1)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid_search=grid.fit(X_train, Y_train) \n",
    "# print optimal number of neighbors\n",
    "print(grid_search.best_params_)\n",
    "# print corresponding training accuracy\n",
    "accuracy = grid_search.best_score_ *100\n",
    "print(\"Accuracy for our training dataset with tuning is : {:.2f}%\".format(accuracy) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sonic-provision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7268041237113402\n",
      "[[67  2  3  1]\n",
      " [15 68  1  0]\n",
      " [ 1  0  3  0]\n",
      " [17  6  7  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.92      0.77        73\n",
      "           2       0.89      0.81      0.85        84\n",
      "           3       0.21      0.75      0.33         4\n",
      "           4       0.75      0.09      0.16        33\n",
      "\n",
      "    accuracy                           0.73       194\n",
      "   macro avg       0.63      0.64      0.53       194\n",
      "weighted avg       0.77      0.73      0.69       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Perform KNN using k=3 neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifierKNN = KNeighborsClassifier(n_neighbors = 3, metric = 'minkowski', p =2) #euclidean metric\n",
    "classifierKNN.fit(X_train,Y_train)\n",
    "\n",
    "#Predicting the Test set results\n",
    "Y_pred = classifierKNN.predict(X_test)\n",
    "\n",
    "#Making the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm.trace()/len(Y_test))\n",
    "print(cm)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abroad-stockholm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n",
      "{'C': 0.01, 'kernel': 'linear'}\n",
      "Accuracy for our training dataset with tuning is : 66.67%\n",
      "SVC(C=0.01, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "#Perform cross validation to find the optimal C value for SVM\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "C_range = list(np.arange(0.01,.1,.01))\n",
    "parameters = {'kernel':['linear'], 'C':C_range}\n",
    "  \n",
    "grid = GridSearchCV(svc, parameters, cv=10, scoring='accuracy', verbose=1)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid_search=grid.fit(X_train[0:300], Y_train[0:300]) #use first 2000 training points for faster computation\n",
    "# print optimal C value\n",
    "print(grid_search.best_params_)\n",
    "# print corresponding training accuracy\n",
    "accuracy = grid_search.best_score_ *100\n",
    "print(\"Accuracy for our training dataset with tuning is : {:.2f}%\".format(accuracy) )\n",
    "# print best estimator\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "developed-afghanistan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6804123711340206\n",
      "[[57 11  4  1]\n",
      " [18 60  2  4]\n",
      " [ 0  1  2  1]\n",
      " [11  6  3 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.78      0.72        73\n",
      "           2       0.77      0.71      0.74        84\n",
      "           3       0.18      0.50      0.27         4\n",
      "           4       0.68      0.39      0.50        33\n",
      "\n",
      "    accuracy                           0.68       194\n",
      "   macro avg       0.57      0.60      0.56       194\n",
      "weighted avg       0.70      0.68      0.68       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SVM using optimal C\n",
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='linear', C=.01, decision_function_shape='ovr')\n",
    "svclassifier.fit(X_train, Y_train)  \n",
    "\n",
    "#Predicting the Test set results\n",
    "Y_pred = svclassifier.predict(X_test)\n",
    "\n",
    "#Making the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm.trace()/len(Y_test))\n",
    "print(cm)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sapphire-redhead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n",
      "{'C': 4.0, 'kernel': 'rbf'}\n",
      "Accuracy for our training dataset with tuning is : 78.67%\n",
      "SVC(C=4.0)\n"
     ]
    }
   ],
   "source": [
    "#Perform cross validation to find the optimal C value for kernel SVM\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "C_range = list(np.arange(1,5,.5))\n",
    "parameters = {'kernel':['rbf'], 'C':C_range}\n",
    "  \n",
    "grid = GridSearchCV(svc, parameters, cv=10, scoring='accuracy', verbose=1)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid_search=grid.fit(X_train[0:300], Y_train[0:300]) #use first 2000 training points for faster computation\n",
    "# print optimal C value\n",
    "print(grid_search.best_params_)\n",
    "# print corresponding training accuracy\n",
    "accuracy = grid_search.best_score_ *100\n",
    "print(\"Accuracy for our training dataset with tuning is : {:.2f}%\".format(accuracy) )\n",
    "# print best estimator\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "angry-blink",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7989690721649485\n",
      "[[58  7  5  3]\n",
      " [ 9 74  0  1]\n",
      " [ 1  0  3  0]\n",
      " [ 5  8  0 20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.79      0.79        73\n",
      "           2       0.83      0.88      0.86        84\n",
      "           3       0.38      0.75      0.50         4\n",
      "           4       0.83      0.61      0.70        33\n",
      "\n",
      "    accuracy                           0.80       194\n",
      "   macro avg       0.71      0.76      0.71       194\n",
      "weighted avg       0.81      0.80      0.80       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Kernel SVM; use gaussian rbf kernel and optimal C value\n",
    "\n",
    "svclassifier = SVC(kernel='rbf', C=4)\n",
    "svclassifier.fit(X_train, Y_train)  # use only first 5000 training data points\n",
    "\n",
    "#Predicting the Test set results\n",
    "Y_pred = svclassifier.predict(X_test)\n",
    "\n",
    "#Making the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm.trace()/len(Y_test))\n",
    "print(cm)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "greenhouse-jones",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7061855670103093\n",
      "[[53 15  4  1]\n",
      " [11 68  0  5]\n",
      " [ 1  0  2  1]\n",
      " [ 9  9  1 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.73      0.72        73\n",
      "           2       0.74      0.81      0.77        84\n",
      "           3       0.29      0.50      0.36         4\n",
      "           4       0.67      0.42      0.52        33\n",
      "\n",
      "    accuracy                           0.71       194\n",
      "   macro avg       0.60      0.61      0.59       194\n",
      "weighted avg       0.71      0.71      0.70       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Neural networks\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='adam', alpha=1e-5,\n",
    "                     hidden_layer_sizes=(20,10), max_iter=1000,random_state=1)\n",
    "\n",
    "clf.fit(X_train, Y_train)\n",
    "#Predicting the Test set results\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "#Making the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm.trace()/len(Y_test))\n",
    "print(cm)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-router",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
